{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPdgbeLXImp1kKobeZwxEmF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9fe035f5f4044671a52fad96fe791f35":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91d5e34d3b2c43d490575488bb7e388a","IPY_MODEL_7c203fd6bb9b43a9a75295467362cdd6","IPY_MODEL_6345847e52a442c6b377f4fef574976e"],"layout":"IPY_MODEL_b9dd2d9edd1847ff974fd6461d847678"}},"91d5e34d3b2c43d490575488bb7e388a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1983f18b5f54d0f8d9f24c297e05515","placeholder":"​","style":"IPY_MODEL_3436abbf03a940e9836f204ca7bb2b7c","value":"Loading checkpoint shards: 100%"}},"7c203fd6bb9b43a9a75295467362cdd6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6e556cc271c44b8b69888fba63cfd57","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc91480e09c84115b8cea1b6eb7a23d9","value":4}},"6345847e52a442c6b377f4fef574976e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce447d244f464221a9586b62ab22c175","placeholder":"​","style":"IPY_MODEL_fc0e5b25338146e995b7f98e370da57a","value":" 4/4 [01:17&lt;00:00, 25.62s/it]"}},"b9dd2d9edd1847ff974fd6461d847678":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1983f18b5f54d0f8d9f24c297e05515":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3436abbf03a940e9836f204ca7bb2b7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6e556cc271c44b8b69888fba63cfd57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc91480e09c84115b8cea1b6eb7a23d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ce447d244f464221a9586b62ab22c175":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc0e5b25338146e995b7f98e370da57a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"collapsed":true,"id":"DA553ZSCYs0P","executionInfo":{"status":"ok","timestamp":1744355599625,"user_tz":-330,"elapsed":13,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}}},"outputs":[],"source":["# # pip installs\n","\n","# !pip install -q datasets==2.21.0 requests torch peft bitsandbytes transformers==4.43.1  trl accelerate sentencepiece tiktoken matplotlib"]},{"cell_type":"code","source":["# pip installs\n","\n","!pip install -q datasets==2.21.0 requests torch peft bitsandbytes transformers trl accelerate sentencepiece tiktoken matplotlib"],"metadata":{"id":"vXACNedFpAk8","executionInfo":{"status":"ok","timestamp":1744355605154,"user_tz":-330,"elapsed":5521,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# imports\n","\n","import os\n","import re\n","import math\n","from tqdm import tqdm\n","from google.colab import userdata\n","from huggingface_hub import login\n","import torch\n","import transformers\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, set_seed\n","from peft import LoraConfig, PeftModel\n","from datasets import load_dataset, Dataset, DatasetDict\n","from datetime import datetime\n","import matplotlib.pyplot as plt"],"metadata":{"id":"uKdClGfzZC90","executionInfo":{"status":"ok","timestamp":1744355617997,"user_tz":-330,"elapsed":12842,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Tokenizers\n","\n","LLAMA_3_1 = \"meta-llama/Meta-Llama-3.1-8B\"\n","QWEN_2_5 = \"Qwen/Qwen2.5-7B\"\n","GEMMA_2 = \"google/gemma-2-9b\"\n","PHI_3 = \"microsoft/Phi-3-medium-4k-instruct\"\n","\n","# Constants\n","\n","BASE_MODEL = LLAMA_3_1\n","HF_USER = \"AJ14314\"\n","DATASET_NAME = f\"{HF_USER}/pricer-data\"\n","MAX_SEQUENCE_LENGTH = 182 # 179 + 3\n","QUANT_4_BIT = True\n","\n","# Used for writing to output in color\n","\n","GREEN = \"\\033[92m\"\n","YELLOW = \"\\033[93m\"\n","RED = \"\\033[91m\"\n","RESET = \"\\033[0m\"\n","COLOR_MAP = {\"red\":RED, \"orange\": YELLOW, \"green\": GREEN}\n","\n","%matplotlib inline"],"metadata":{"id":"igA5dJ7lZneO","executionInfo":{"status":"ok","timestamp":1744355618000,"user_tz":-330,"elapsed":29,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Log in to HuggingFace\n","\n","hf_token = userdata.get('HF_TOKEN')\n","login(hf_token, add_to_git_credential=True)"],"metadata":{"id":"3-2UfsxlZyPm","executionInfo":{"status":"ok","timestamp":1744355619006,"user_tz":-330,"elapsed":1034,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def investigate_tokenizer(model_name):\n","    print(\"Investigating tokenizer for \", model_name)\n","    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","    for number in [0, 2, 10, 100, 999, 1000]:\n","        tokens = tokenizer.encode(str(number), add_special_tokens=False)\n","        print(f\"The tokens for {number}: {tokens}\")"],"metadata":{"id":"NdfcJvBeaH4J","executionInfo":{"status":"ok","timestamp":1744355619020,"user_tz":-330,"elapsed":12,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Now we will try this with each model: LLAMA_3_1, QWEN_2_5, GEMMA_2, PHI_3\n","\n","print(\"Llama 3.1: \")\n","investigate_tokenizer(LLAMA_3_1)\n","print(\"\\nQwen: \")\n","investigate_tokenizer(QWEN_2_5)\n","print(\"\\nGemma: \")\n","investigate_tokenizer(GEMMA_2)\n","print(\"\\nPhi: \")\n","investigate_tokenizer(PHI_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iopr4P8XasDS","executionInfo":{"status":"ok","timestamp":1744355626119,"user_tz":-330,"elapsed":7098,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"1f7cae22-0b98-4e7f-e1cf-420b796ccd6b","collapsed":true},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Llama 3.1: \n","Investigating tokenizer for  meta-llama/Meta-Llama-3.1-8B\n","The tokens for 0: [15]\n","The tokens for 2: [17]\n","The tokens for 10: [605]\n","The tokens for 100: [1041]\n","The tokens for 999: [5500]\n","The tokens for 1000: [1041, 15]\n","\n","Qwen: \n","Investigating tokenizer for  Qwen/Qwen2.5-7B\n","The tokens for 0: [15]\n","The tokens for 2: [17]\n","The tokens for 10: [16, 15]\n","The tokens for 100: [16, 15, 15]\n","The tokens for 999: [24, 24, 24]\n","The tokens for 1000: [16, 15, 15, 15]\n","\n","Gemma: \n","Investigating tokenizer for  google/gemma-2-9b\n","The tokens for 0: [235276]\n","The tokens for 2: [235284]\n","The tokens for 10: [235274, 235276]\n","The tokens for 100: [235274, 235276, 235276]\n","The tokens for 999: [235315, 235315, 235315]\n","The tokens for 1000: [235274, 235276, 235276, 235276]\n","\n","Phi: \n","Investigating tokenizer for  microsoft/Phi-3-medium-4k-instruct\n","The tokens for 0: [29871, 29900]\n","The tokens for 2: [29871, 29906]\n","The tokens for 10: [29871, 29896, 29900]\n","The tokens for 100: [29871, 29896, 29900, 29900]\n","The tokens for 999: [29871, 29929, 29929, 29929]\n","The tokens for 1000: [29871, 29896, 29900, 29900, 29900]\n"]}]},{"cell_type":"markdown","source":["# Load our data\n","\n","We uploaded it to Hugging Face, so it's easy to retrieve it now"],"metadata":{"id":"HzINKZiia4Y6"}},{"cell_type":"code","source":["dataset  = load_dataset(DATASET_NAME)\n","train = dataset['train']\n","test = dataset['test']"],"metadata":{"id":"s2BlhJ3wau7l","executionInfo":{"status":"ok","timestamp":1744355629893,"user_tz":-330,"elapsed":3772,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XDX0YWcfcbnk","executionInfo":{"status":"ok","timestamp":1744355629910,"user_tz":-330,"elapsed":15,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"2fd8b797-cb81-4617-bbde-6b237b7a06ef"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'text': 'How much does this cost to the nearest dollar?\\n\\nDelphi FG0166 Fuel Pump Module\\nDelphi brings 80 years of OE Heritage into each Delphi pump, ensuring quality and fitment for each Delphi part. Part is validated, tested and matched to the right vehicle application Delphi brings 80 years of OE Heritage into each Delphi assembly, ensuring quality and fitment for each Delphi part Always be sure to check and clean fuel tank to avoid unnecessary returns Rigorous OE-testing ensures the pump can withstand extreme temperatures Brand Delphi, Fit Type Vehicle Specific Fit, Dimensions LxWxH 19.7 x 7.7 x 5.1 inches, Weight 2.2 Pounds, Auto Part Position Unknown, Operation Mode Mechanical, Manufacturer Delphi, Model FUEL PUMP, Dimensions 19.7\\n\\nPrice is $227.00',\n"," 'price': 226.95}"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["test[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FvQdezLIcnjp","executionInfo":{"status":"ok","timestamp":1744355629936,"user_tz":-330,"elapsed":25,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"efa06cc3-819c-4188-fade-0331d58f974d"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'text': \"How much does this cost to the nearest dollar?\\n\\nOEM AC Compressor w/A/C Repair Kit For Ford F150 F-150 V8 & Lincoln Mark LT 2007 2008 - BuyAutoParts NEW\\nAs one of the world's largest automotive parts suppliers, our parts are trusted every day by mechanics and vehicle owners worldwide. This A/C Compressor and Components Kit is manufactured and tested to the strictest OE standards for unparalleled performance. Built for trouble-free ownership and 100% visually inspected and quality tested, this A/C Compressor and Components Kit is backed by our 100% satisfaction guarantee. Guaranteed Exact Fit for easy installation 100% BRAND NEW, premium ISO/TS 16949 quality - tested to meet or exceed OEM specifications Engineered for superior durability, backed by industry-leading unlimited-mileage warranty Included in this K\\n\\nPrice is $\",\n"," 'price': 374.41}"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["# Prepare our Base Llama Model for evaluation\n","\n","Load our base model with 4 bit quantization and try out 1 example"],"metadata":{"id":"l6i9lTYhbudR"}},{"cell_type":"code","source":["## Pick the right qunatization\n","\n","if QUANT_4_BIT:\n","    quant_config = BitsAndBytesConfig(\n","        load_in_4bit=True,\n","        bnb_4bit_use_double_quant=True,\n","        bnb_4bit_compute_dtype=torch.bfloat16,\n","        bnb_4bit_quant_type=\"nf4\"\n","    )\n","else:\n","    quant_config  = BitsAndBytesConfig(\n","        load_in_8bit = True,\n","        bnb_8bit_compute_dtype=torch.bfloat16\n","    )"],"metadata":{"id":"NDU8AbYfboSU","executionInfo":{"status":"ok","timestamp":1744355629949,"user_tz":-330,"elapsed":11,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["quant_config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MrFvlThdKhn","executionInfo":{"status":"ok","timestamp":1744355629967,"user_tz":-330,"elapsed":16,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"2ab72da0-b0ca-4108-d493-8e4e1c57b58a"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BitsAndBytesConfig {\n","  \"_load_in_4bit\": true,\n","  \"_load_in_8bit\": false,\n","  \"bnb_4bit_compute_dtype\": \"bfloat16\",\n","  \"bnb_4bit_quant_storage\": \"uint8\",\n","  \"bnb_4bit_quant_type\": \"nf4\",\n","  \"bnb_4bit_use_double_quant\": true,\n","  \"llm_int8_enable_fp32_cpu_offload\": false,\n","  \"llm_int8_has_fp16_weight\": false,\n","  \"llm_int8_skip_modules\": null,\n","  \"llm_int8_threshold\": 6.0,\n","  \"load_in_4bit\": true,\n","  \"load_in_8bit\": false,\n","  \"quant_method\": \"bitsandbytes\"\n","}"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Load the Tokenizer and the Model\n","\n","tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\"\n","\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    BASE_MODEL,\n","    # quantization_config=quant_config\n","    device_map=\"auto\",  # Remove device_map=\"auto\" since BitsAndBytesConfig handles it\n",")\n","base_model.generation_config.pad_token_id = tokenizer.pad_token_id\n","\n","print(f\"Memory footprint: {base_model.get_memory_footprint() / 1e9:.1f} GB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["9fe035f5f4044671a52fad96fe791f35","91d5e34d3b2c43d490575488bb7e388a","7c203fd6bb9b43a9a75295467362cdd6","6345847e52a442c6b377f4fef574976e","b9dd2d9edd1847ff974fd6461d847678","a1983f18b5f54d0f8d9f24c297e05515","3436abbf03a940e9836f204ca7bb2b7c","b6e556cc271c44b8b69888fba63cfd57","bc91480e09c84115b8cea1b6eb7a23d9","ce447d244f464221a9586b62ab22c175","fc0e5b25338146e995b7f98e370da57a"]},"id":"knirRZT3kZdo","executionInfo":{"status":"ok","timestamp":1744355709832,"user_tz":-330,"elapsed":79863,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"5020f422-0884-40a8-f43b-bc145a74c144"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fe035f5f4044671a52fad96fe791f35"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"]},{"output_type":"stream","name":"stdout","text":["Memory footprint: 32.1 GB\n"]}]},{"cell_type":"code","source":["def extract_price(s):\n","    if \"Price is $\" in s:\n","      contents = s.split(\"Price is $\")[1]\n","      contents = contents.replace(',','').replace('$','')\n","      match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", contents)\n","      return float(match.group()) if match else 0\n","    return 0"],"metadata":{"id":"Vn4RYAkwdIEk","executionInfo":{"status":"ok","timestamp":1744355723680,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["extract_price(\"Price is $999 blah blah so cheap\")"],"metadata":{"id":"ZdlakUIGeXdT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744355725395,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"cb919da1-9fc1-45a0-cecf-e250ab43efc8"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["999.0"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["def model_predict(prompt):\n","    set_seed(42)\n","    inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n","    attention_mask = torch.ones(inputs.shape, device=\"cuda\")\n","    outputs = base_model.generate(inputs, max_new_tokens=4, attention_mask=attention_mask, num_return_sequences=1)\n","    response = tokenizer.decode(outputs[0])\n","    return extract_price(response)"],"metadata":{"id":"WZxFBdrXlUMX","executionInfo":{"status":"ok","timestamp":1744355975353,"user_tz":-330,"elapsed":42,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["model_predict(test[0]['text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KrYpZYu6t98u","executionInfo":{"status":"ok","timestamp":1744356126219,"user_tz":-330,"elapsed":145873,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"3e162bf6-024c-463e-a3b6-6afd43724044"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1800.0"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["# Evaluation!\n","\n","Trying out our base Llama 3.1 model against the Test dataset"],"metadata":{"id":"QDr1GXFM1S9-"}},{"cell_type":"code","source":["class Tester:\n","\n","    def __init__(self, predictor, data, title=None, size=250):\n","        self.predictor = predictor\n","        self.data = data\n","        self.title = title or predictor.__name__.replace(\"_\", \" \").title()\n","        self.size = size\n","        self.guesses = []\n","        self.truths = []\n","        self.errors = []\n","        self.sles = []\n","        self.colors = []\n","\n","    def color_for(self, error, truth):\n","        if error<40 or error/truth < 0.2:\n","            return \"green\"\n","        elif error<80 or error/truth < 0.4:\n","            return \"orange\"\n","        else:\n","            return \"red\"\n","\n","    def run_datapoint(self, i):\n","        datapoint = self.data[i]\n","        guess = self.predictor(datapoint[\"text\"])\n","        truth = datapoint[\"price\"]\n","        error = abs(guess - truth)\n","        log_error = math.log(truth+1) - math.log(guess+1)\n","        sle = log_error ** 2\n","        color = self.color_for(error, truth)\n","        title = datapoint[\"text\"].split(\"\\n\\n\")[1][:20] + \"...\"\n","        self.guesses.append(guess)\n","        self.truths.append(truth)\n","        self.errors.append(error)\n","        self.sles.append(sle)\n","        self.colors.append(color)\n","        print(f\"{COLOR_MAP[color]}{i+1}: Guess: ${guess:,.2f} Truth: ${truth:,.2f} Error: ${error:,.2f} SLE: {sle:,.2f} Item: {title}{RESET}\")\n","\n","    def chart(self, title):\n","        max_error = max(self.errors)\n","        plt.figure(figsize=(12, 8))\n","        max_val = max(max(self.truths), max(self.guesses))\n","        plt.plot([0, max_val], [0, max_val], color='deepskyblue', lw=2, alpha=0.6)\n","        plt.scatter(self.truths, self.guesses, s=3, c=self.colors)\n","        plt.xlabel('Ground Truth')\n","        plt.ylabel('Model Estimate')\n","        plt.xlim(0, max_val)\n","        plt.ylim(0, max_val)\n","        plt.title(title)\n","        plt.show()\n","\n","    def report(self):\n","        average_error = sum(self.errors) / self.size\n","        rmsle = math.sqrt(sum(self.sles) / self.size)\n","        hits = sum(1 for color in self.colors if color==\"green\")\n","        title = f\"{self.title} Error=${average_error:,.2f} RMSLE={rmsle:,.2f} Hits={hits/self.size*100:.1f}%\"\n","        self.chart(title)\n","\n","    def run(self):\n","        self.error = 0\n","        for i in range(self.size):\n","            self.run_datapoint(i)\n","        self.report()\n","\n","    @classmethod\n","    def test(cls, function, data):\n","        cls(function, data).run()"],"metadata":{"id":"SgCpQyJtt_LZ","executionInfo":{"status":"ok","timestamp":1744357907464,"user_tz":-330,"elapsed":6,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["Tester.test(model_predict, test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z388O56O1Rll","outputId":"cece0a10-1104-45d3-8ac5-cadb28961ad5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[91m1: Guess: $1,800.00 Truth: $374.41 Error: $1,425.59 SLE: 2.46 Item: OEM AC Compressor w/...\u001b[0m\n","\u001b[91m2: Guess: $25.00 Truth: $225.11 Error: $200.11 SLE: 4.68 Item: Motorcraft YB3125 Fa...\u001b[0m\n","\u001b[93m3: Guess: $19.99 Truth: $61.68 Error: $41.69 SLE: 1.20 Item: Dorman Front Washer ...\u001b[0m\n","\u001b[91m4: Guess: $299.99 Truth: $599.99 Error: $300.00 SLE: 0.48 Item: HP Premium HD Plus T...\u001b[0m\n","\u001b[92m5: Guess: $7.99 Truth: $16.99 Error: $9.00 SLE: 0.48 Item: Super Switch Pickup ...\u001b[0m\n","\u001b[92m6: Guess: $7.99 Truth: $31.99 Error: $24.00 SLE: 1.69 Item: Horror Bookmarks, Re...\u001b[0m\n","\u001b[92m7: Guess: $89.99 Truth: $101.79 Error: $11.80 SLE: 0.01 Item: SK6241 - Stinger 4 G...\u001b[0m\n","\u001b[92m8: Guess: $299.00 Truth: $289.00 Error: $10.00 SLE: 0.00 Item: Godox ML60Bi LED Lig...\u001b[0m\n","\u001b[91m9: Guess: $299.00 Truth: $635.86 Error: $336.86 SLE: 0.57 Item: Randall G3 Plus Comb...\u001b[0m\n","\u001b[93m10: Guess: $19.99 Truth: $65.99 Error: $46.00 SLE: 1.35 Item: HOLDWILL 6 Pack LED ...\u001b[0m\n","\u001b[91m11: Guess: $89.95 Truth: $254.21 Error: $164.26 SLE: 1.06 Item: Viking Horns 3 Gallo...\u001b[0m\n","\u001b[93m12: Guess: $299.00 Truth: $412.99 Error: $113.99 SLE: 0.10 Item: CURT 70110 Custom To...\u001b[0m\n","\u001b[91m13: Guess: $19.99 Truth: $205.50 Error: $185.51 SLE: 5.23 Item: Solar HAMMERED BRONZ...\u001b[0m\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nYH3pA0w1X5U"},"execution_count":null,"outputs":[]}]}