{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMVE8vQBN0kZtYaC254L+Xb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"42b06f7ac4784a5dbda401336874c7e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fda3f71bf158462b82fe8fcff835b615","IPY_MODEL_f9c8825cc41f45df890ee1226be2d12d","IPY_MODEL_b77e3171899540ecbe0480045553adf4"],"layout":"IPY_MODEL_1f64bdb4cbb74116a90550735bc8d19b"}},"fda3f71bf158462b82fe8fcff835b615":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b8d2f982172460ba6e24b6a70508890","placeholder":"​","style":"IPY_MODEL_2cf6101e2558498caa89626c482b9441","value":"Loading checkpoint shards: 100%"}},"f9c8825cc41f45df890ee1226be2d12d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f625a5292b054d9b8500405b7a3104c0","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e114bdfc169548ac924a4e3f3c54391e","value":4}},"b77e3171899540ecbe0480045553adf4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf0cc6cff72648858cc535a69b15ddca","placeholder":"​","style":"IPY_MODEL_53b77ee80d2d4e1b8176334588c5d3fd","value":" 4/4 [01:23&lt;00:00, 18.37s/it]"}},"1f64bdb4cbb74116a90550735bc8d19b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b8d2f982172460ba6e24b6a70508890":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cf6101e2558498caa89626c482b9441":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f625a5292b054d9b8500405b7a3104c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e114bdfc169548ac924a4e3f3c54391e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf0cc6cff72648858cc535a69b15ddca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53b77ee80d2d4e1b8176334588c5d3fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e423e0997af54a5388449a52de72e7c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08473195c3dc43ec84a5fdcb9da83fff","IPY_MODEL_315eb6a9f3e14cc28539863a271ca6d6","IPY_MODEL_6596ecc8593d451ab6edaaa13c3a5f83"],"layout":"IPY_MODEL_47d55ed41bf645c7be1127257ad3db09"}},"08473195c3dc43ec84a5fdcb9da83fff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccd700d98d1340eb8232cf34dfa41242","placeholder":"​","style":"IPY_MODEL_96e5ae8ba8014566b2acf6d95bc842c3","value":"Loading checkpoint shards: 100%"}},"315eb6a9f3e14cc28539863a271ca6d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7768cd86e75b4450880ddfc8b422f165","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc847b2f0ddc422fbec4e28384472b22","value":4}},"6596ecc8593d451ab6edaaa13c3a5f83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edff571be3db4521bf4eaf7622e56826","placeholder":"​","style":"IPY_MODEL_dd2bc46dee4a43ec8aaf4501ac9f22aa","value":" 4/4 [01:14&lt;00:00, 16.29s/it]"}},"47d55ed41bf645c7be1127257ad3db09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccd700d98d1340eb8232cf34dfa41242":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96e5ae8ba8014566b2acf6d95bc842c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7768cd86e75b4450880ddfc8b422f165":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc847b2f0ddc422fbec4e28384472b22":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"edff571be3db4521bf4eaf7622e56826":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd2bc46dee4a43ec8aaf4501ac9f22aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d905965192bb49bf9fb6dee79624c2b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33390f51f46442a5adac133fcba42431","IPY_MODEL_6dc140cff3f549a480f6596d42f518c4","IPY_MODEL_88e5a6a575144b67b882fb43948d1282"],"layout":"IPY_MODEL_b455ad7582b94a8a84e67db473d27469"}},"33390f51f46442a5adac133fcba42431":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_625b707f288f4021af40819e5a9ef7cf","placeholder":"​","style":"IPY_MODEL_6b5660546a734069bb7dc36705ff55ef","value":"adapter_model.safetensors: 100%"}},"6dc140cff3f549a480f6596d42f518c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8136100efa4f4c25b56fa8938d32306c","max":109086416,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bdcc1bbfa3864a49a196465c98dde880","value":109086416}},"88e5a6a575144b67b882fb43948d1282":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80243ba40e5948528ac76b24dba39309","placeholder":"​","style":"IPY_MODEL_0a2eec38b523431780730d239c816a5b","value":" 109M/109M [00:04&lt;00:00, 23.4MB/s]"}},"b455ad7582b94a8a84e67db473d27469":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"625b707f288f4021af40819e5a9ef7cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b5660546a734069bb7dc36705ff55ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8136100efa4f4c25b56fa8938d32306c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdcc1bbfa3864a49a196465c98dde880":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"80243ba40e5948528ac76b24dba39309":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a2eec38b523431780730d239c816a5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lSgYucRQj5LL"},"outputs":[],"source":["# pip installs\n","\n","!pip install -q datasets requests torch peft bitsandbytes transformers trl accelerate sentencepiece"]},{"cell_type":"code","source":["# imports\n","\n","import os\n","import re\n","import math\n","from tqdm import tqdm\n","from google.colab import userdata\n","from huggingface_hub import login\n","import torch\n","import transformers\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, set_seed\n","from peft import LoraConfig, PeftModel\n","from datetime import datetime"],"metadata":{"id":"NTnwUUWBp5eX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  Constants\n","\n","BASE_MODEL = \"meta-llama/Meta-Llama-3.1-8B\"\n","FINETUNED_MODEL = f\"AJ14314/pricer-10-04-2025\"\n","\n","# Hyperparameters for QLoRA Fine-Tuning\n","\n","LORA_R = 32\n","LORA_ALPHA = 64\n","TARGET_MODULES = [\"q_proj\",  \"v_proj\", \"k_proj\", \"o_proj\"]"],"metadata":{"id":"sAom0jenqZ-W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Log in to HuggingFace\n","\n","hf_token = userdata.get('HF_TOKEN')\n","login(hf_token, add_to_git_credential=True)"],"metadata":{"id":"xgllM1nlqrbs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the Base Model without quantization\n","\n","base_model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map=\"auto\")"],"metadata":{"collapsed":true,"id":"e7IhldTYrl-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Memory footprint: {base_model.get_memory_footprint() / 1e9:,.1f} GB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XQhv7drVrxnB","executionInfo":{"status":"ok","timestamp":1744288562219,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"23de1412-3817-4651-817d-876a1f2b39fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Memory footprint: 32.1 GB\n"]}]},{"cell_type":"code","source":["base_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Jf9KRnUosc5v","executionInfo":{"status":"ok","timestamp":1744288637867,"user_tz":-330,"elapsed":12,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"ac52d942-15b2-46f6-da84-21f451d450ab"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LlamaForCausalLM(\n","  (model): LlamaModel(\n","    (embed_tokens): Embedding(128256, 4096)\n","    (layers): ModuleList(\n","      (0-31): 32 x LlamaDecoderLayer(\n","        (self_attn): LlamaAttention(\n","          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n","          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n","          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","        )\n","        (mlp): LlamaMLP(\n","          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n","          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n","          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","      )\n","    )\n","    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n","    (rotary_emb): LlamaRotaryEmbedding()\n","  )\n","  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## Restart your session for 8 bit Quantization\n","\n","In order to load the next model and clear out the cache of the last model, you'll now need to go to Runtime >> Restart session and run the initial cells (installs and imports and HuggingFace login) again.\n","\n","This is to clean out the GPU."],"metadata":{"id":"wpxvPsVstwuO"}},{"cell_type":"code","source":["# Load the base Model using 8 bit\n","\n","quant_config = BitsAndBytesConfig(load_in_8Bit = True)\n","\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    BASE_MODEL,\n","    quantization_config=quant_config,\n","    device_map=\"auto\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["42b06f7ac4784a5dbda401336874c7e2","fda3f71bf158462b82fe8fcff835b615","f9c8825cc41f45df890ee1226be2d12d","b77e3171899540ecbe0480045553adf4","1f64bdb4cbb74116a90550735bc8d19b","8b8d2f982172460ba6e24b6a70508890","2cf6101e2558498caa89626c482b9441","f625a5292b054d9b8500405b7a3104c0","e114bdfc169548ac924a4e3f3c54391e","cf0cc6cff72648858cc535a69b15ddca","53b77ee80d2d4e1b8176334588c5d3fd"]},"id":"xGFO9Xckt3sZ","executionInfo":{"status":"ok","timestamp":1744289411333,"user_tz":-330,"elapsed":86075,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"e050723b-ef2f-4221-e4e5-e6bbddc99c3b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42b06f7ac4784a5dbda401336874c7e2"}},"metadata":{}}]},{"cell_type":"code","source":["print(f\"Memory footprint: {base_model.get_memory_footprint() / 1e9:,.1f} GB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pDuQU6FKu3ZP","executionInfo":{"status":"ok","timestamp":1744289547008,"user_tz":-330,"elapsed":48,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"0b849d39-42c9-4564-982a-2ca77b6741ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Memory footprint: 5.6 GB\n"]}]},{"cell_type":"code","source":["base_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"H1OGr0KSv_4G","executionInfo":{"status":"ok","timestamp":1744289549439,"user_tz":-330,"elapsed":12,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"92b59d21-eedb-4b22-b644-26adb847dca9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LlamaForCausalLM(\n","  (model): LlamaModel(\n","    (embed_tokens): Embedding(128256, 4096)\n","    (layers): ModuleList(\n","      (0-31): 32 x LlamaDecoderLayer(\n","        (self_attn): LlamaAttention(\n","          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","        )\n","        (mlp): LlamaMLP(\n","          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","      )\n","    )\n","    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n","    (rotary_emb): LlamaRotaryEmbedding()\n","  )\n","  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["## Restart your session for 4 bit Quantization\n","\n","In order to load the next model and clear out the cache of the last model, you'll now need to go to Runtime >> Restart session and run the initial cells (installs and imports and HuggingFace login) again.\n","\n","This is to clean out the GPU."],"metadata":{"id":"lyWO1Yx_xgef"}},{"cell_type":"code","source":["# Load the Tokenizer and the Base Model using 4 bit\n","\n","quant_config = BitsAndBytesConfig(\n","    load_in_4Bit = True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n","    bnb_4bit_quant_type=\"nf4\")\n","\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    BASE_MODEL,\n","    quantization_config=quant_config,\n","    device_map=\"auto\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["e423e0997af54a5388449a52de72e7c5","08473195c3dc43ec84a5fdcb9da83fff","315eb6a9f3e14cc28539863a271ca6d6","6596ecc8593d451ab6edaaa13c3a5f83","47d55ed41bf645c7be1127257ad3db09","ccd700d98d1340eb8232cf34dfa41242","96e5ae8ba8014566b2acf6d95bc842c3","7768cd86e75b4450880ddfc8b422f165","cc847b2f0ddc422fbec4e28384472b22","edff571be3db4521bf4eaf7622e56826","dd2bc46dee4a43ec8aaf4501ac9f22aa"]},"id":"Vg3EneBOwkvX","executionInfo":{"status":"ok","timestamp":1744290585242,"user_tz":-330,"elapsed":77060,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"c7e63d6a-d62b-4477-dd88-6f9872ea9149"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e423e0997af54a5388449a52de72e7c5"}},"metadata":{}}]},{"cell_type":"code","source":["print(f\"Memory footprint: {base_model.get_memory_footprint() / 1e9:,.1f} GB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-VmNvdIyfNd","executionInfo":{"status":"ok","timestamp":1744290588460,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"2abb65c5-d046-4557-d663-dc46bd112030"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Memory footprint: 5.6 GB\n"]}]},{"cell_type":"code","source":["base_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"tD6ipLCayh3p","executionInfo":{"status":"ok","timestamp":1744290592528,"user_tz":-330,"elapsed":20,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"15fa650e-6e94-4d3e-8b26-bf0b1dd15699"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LlamaForCausalLM(\n","  (model): LlamaModel(\n","    (embed_tokens): Embedding(128256, 4096)\n","    (layers): ModuleList(\n","      (0-31): 32 x LlamaDecoderLayer(\n","        (self_attn): LlamaAttention(\n","          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","        )\n","        (mlp): LlamaMLP(\n","          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","      )\n","    )\n","    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n","    (rotary_emb): LlamaRotaryEmbedding()\n","  )\n","  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["## Loading Fine-Tuned Model from hugging face and we need some config so added in the repo\n","\n","https://huggingface.co/AJ14314/pricer-10-04-2025"],"metadata":{"id":"Gnwh6g--5GQ-"}},{"cell_type":"code","source":["fine_tuned_model = PeftModel.from_pretrained(base_model, FINETUNED_MODEL)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["d905965192bb49bf9fb6dee79624c2b1","33390f51f46442a5adac133fcba42431","6dc140cff3f549a480f6596d42f518c4","88e5a6a575144b67b882fb43948d1282","b455ad7582b94a8a84e67db473d27469","625b707f288f4021af40819e5a9ef7cf","6b5660546a734069bb7dc36705ff55ef","8136100efa4f4c25b56fa8938d32306c","bdcc1bbfa3864a49a196465c98dde880","80243ba40e5948528ac76b24dba39309","0a2eec38b523431780730d239c816a5b"]},"id":"WtAFjyDz0p-T","executionInfo":{"status":"ok","timestamp":1744291767092,"user_tz":-330,"elapsed":7002,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"5060c1f7-b69f-4da3-aeb1-df71f842c1de"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["adapter_model.safetensors:   0%|          | 0.00/109M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d905965192bb49bf9fb6dee79624c2b1"}},"metadata":{}}]},{"cell_type":"code","source":["print(f\"Memory footprint: {base_model.get_memory_footprint() / 1e9:,.1f} GB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J7hPNBCF04xb","executionInfo":{"status":"ok","timestamp":1744291860328,"user_tz":-330,"elapsed":38,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"789946c6-7e50-43ff-962b-21a40e5250cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Memory footprint: 5.7 GB\n"]}]},{"cell_type":"code","source":["base_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"KE0cgKm45FUU","executionInfo":{"status":"ok","timestamp":1744291862358,"user_tz":-330,"elapsed":14,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"b785b977-7d5a-451a-bfd7-34502ce170dd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LlamaForCausalLM(\n","  (model): LlamaModel(\n","    (embed_tokens): Embedding(128256, 4096)\n","    (layers): ModuleList(\n","      (0-31): 32 x LlamaDecoderLayer(\n","        (self_attn): LlamaAttention(\n","          (q_proj): lora.Linear4bit(\n","            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.1, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=32, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=32, out_features=4096, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","          (k_proj): lora.Linear4bit(\n","            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.1, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=32, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=32, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","          (v_proj): lora.Linear4bit(\n","            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.1, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=32, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=32, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","          (o_proj): lora.Linear4bit(\n","            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.1, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=32, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=32, out_features=4096, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","        )\n","        (mlp): LlamaMLP(\n","          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","      )\n","    )\n","    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n","    (rotary_emb): LlamaRotaryEmbedding()\n","  )\n","  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",")"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# Each of the Target Modules has 2 LoRA Adaptor matrices, called lora_A and lora_B\n","# These are designed so that weights can be adapted by adding alpha * lora_A * lora_B\n","# Let's count the number of weights using their dimensions:\n","\n","# See the matrix dimensions above\n","lora_q_proj = 4096 * 32 + 4096 * 32\n","lora_k_proj = 4096 * 32 + 1024 * 32\n","lora_v_proj = 4096 * 32 + 1024 * 32\n","lora_o_proj = 4096 * 32 + 4096 * 32\n","\n","# Each layer comes to\n","lora_layer = lora_q_proj + lora_k_proj + lora_v_proj + lora_o_proj\n","\n","# There are 32 layers\n","params = lora_layer * 32\n","\n","# So the total size in MB is\n","size = (params * 4) / 1_000_000\n","\n","print(f\"Total number of params: {params:,} and size {size:,.1f}MB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0XC99II95Za2","executionInfo":{"status":"ok","timestamp":1744292019775,"user_tz":-330,"elapsed":6,"user":{"displayName":"Anand Jain","userId":"02087459851710183945"}},"outputId":"3e801103-0c6c-4340-8329-63b2c06cc593"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of params: 27,262,976 and size 109.1MB\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xzQMXuGl5_2m"},"execution_count":null,"outputs":[]}]}