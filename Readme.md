# LLM Learning Project

A comprehensive project for experimenting with Large Language Models (LLMs), vector databases, and AI tools. This repository includes implementations of RAG, stock analysis, and various LLM integrations.

## ğŸš€ Features

- **Multiple LLM Integrations**
  - OpenAI
  - Google Gemini
  - Anthropic Claude
  - Ollama for local LLM deployment

- **Vector Databases**
  - FAISS
  - ChromaDB
  - Document embeddings with sentence-transformers

- **Tools & Frameworks**
  - LangChain for orchestration
  - Hugging Face Transformers
  - Gradio for UI interfaces
  - Jupyter for interactive development

- **Data Processing**
  - Stock analysis tools
  - Unstructured data handling
  - Audio processing with pydub
  - Web scraping with BeautifulSoup4

## ğŸ“¦ Dependencies

Core dependencies include:

```txt
# AI/ML
torch
transformers
openai
google-generativeai
anthropic
ollama
sentence_transformers
bitsandbytes

# Data Processing
numpy
pandas
scipy
scikit-learn

# Vector Databases
faiss-cpu
chromadb

# LangChain Ecosystem
langchain
langchain-openai
langchain_experimental
langchain_chroma

# Visualization
plotly
matplotlib
jupyter-dash

# Development Tools
jupyterlab
python-dotenv
gradio
modal
```

## ğŸ› ï¸ Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/llm_learning.git
cd llm_learning
```

2. Create a virtual environment:
```bash
python -m venv venv
.\venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Setup environment variables:
```bash
copy .env.example .env
# Edit .env with your API keys
```

## ğŸ“š Project Structure

```
llm_learning/
â”œâ”€â”€ Practise_Codes/
â”‚   â”œâ”€â”€ Gemini.ipynb           # Google Gemini experiments
â”‚   â”œâ”€â”€ HuggingFace.ipynb      # HuggingFace models usage
â”‚   â”œâ”€â”€ Tokenizers.ipynb       # Tokenization experiments
â”‚   â”œâ”€â”€ project_s.ipynb        # Stock analysis
â”‚   â”œâ”€â”€ rag_implementation_chrome.ipynb
â”‚   â”œâ”€â”€ rag_implementation_faiss.ipynb
â”‚   â””â”€â”€ nse_stock_analysis/    # Stock analysis tools
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ .env                      # Environment variables
```

## ğŸ’¡ Usage

1. Start JupyterLab:
```bash
jupyter lab
```

2. Navigate to `Practise_Codes/` and explore the notebooks:
   - `Gemini.ipynb` for Google Gemini experiments
   - `rag_implementation_*.ipynb` for RAG implementations
   - `project_s.ipynb` for stock analysis

## ğŸ”§ Development Tools

- **Code Acceleration**
  - `accelerate` for hardware optimization
  - `bitsandbytes` for quantization
  - `psutil` for system monitoring

- **Data Sources**
  - `feedparser` for RSS feeds
  - `speedtest-cli` for network testing
  - `beautifulsoup4` for web scraping

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- LangChain community
- Hugging Face team
- ChromaDB developers
- FAISS developers

---
*Note: Make sure to check the individual notebook documentation for specific usage examples and requirements.*